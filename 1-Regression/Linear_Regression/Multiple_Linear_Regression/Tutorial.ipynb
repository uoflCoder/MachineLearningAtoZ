{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tylor/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.610</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.593</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   36.71</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 23 Dec 2017</td> <th>  Prob (F-statistic):</th> <td>2.50e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:07:00</td>     <th>  Log-Likelihood:    </th> <td> -577.13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1160.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1166.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 2.022e+04</td> <td> 1.77e+04</td> <td>    1.143</td> <td> 0.259</td> <td>-1.54e+04</td> <td> 5.58e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.3237</td> <td>    0.131</td> <td>    2.468</td> <td> 0.017</td> <td>    0.060</td> <td>    0.588</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.2488</td> <td>    0.030</td> <td>    8.281</td> <td> 0.000</td> <td>    0.188</td> <td>    0.309</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 6.584</td> <th>  Durbin-Watson:     </th> <td>   1.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.037</td> <th>  Jarque-Bera (JB):  </th> <td>   6.524</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.512</td> <th>  Prob(JB):          </th> <td>  0.0383</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.443</td> <th>  Cond. No.          </th> <td>1.30e+06</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.610\n",
       "Model:                            OLS   Adj. R-squared:                  0.593\n",
       "Method:                 Least Squares   F-statistic:                     36.71\n",
       "Date:                Sat, 23 Dec 2017   Prob (F-statistic):           2.50e-10\n",
       "Time:                        14:07:00   Log-Likelihood:                -577.13\n",
       "No. Observations:                  50   AIC:                             1160.\n",
       "Df Residuals:                      47   BIC:                             1166.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       2.022e+04   1.77e+04      1.143      0.259   -1.54e+04    5.58e+04\n",
       "x1             0.3237      0.131      2.468      0.017       0.060       0.588\n",
       "x2             0.2488      0.030      8.281      0.000       0.188       0.309\n",
       "==============================================================================\n",
       "Omnibus:                        6.584   Durbin-Watson:                   1.279\n",
       "Prob(Omnibus):                  0.037   Jarque-Bera (JB):                6.524\n",
       "Skew:                          -0.512   Prob(JB):                       0.0383\n",
       "Kurtosis:                       4.443   Cond. No.                     1.30e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.3e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Nov 22 10:45:16 2017\n",
    "\n",
    "@author: Tylor Cornett\n",
    "\"\"\"\n",
    "#Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#Import the Dataset\n",
    "dataset = pd.read_csv('50_Startups.csv')\n",
    "\n",
    "\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 4].values\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:, 3] = labelencoder_X.fit_transform(X[:, 3])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [3])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "\n",
    "#Avoiding the Dummy Variable Trap\n",
    "X = X[:,1:]\n",
    "\n",
    "#Split into Training and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "\n",
    "#Feature Scaling\n",
    "#Don't need to do this for some reason. But will do it anyway\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "\n",
    "\n",
    "#Fitting Multiple Linear Regression to the Training Set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "#Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "\n",
    "#Building the optimal model using Backward Elimination\n",
    "import statsmodels.formula.api as sm\n",
    "X = np.append(arr=np.ones((len(X[:,1]),1), dtype=int), values=X, axis=1)\n",
    "X_opt = X[:, [0,4,5]]\n",
    "\n",
    "#OLS, ordinary least squares\n",
    "regressor_ols = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_ols.summary()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
